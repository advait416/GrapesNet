{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/advait416/Grapesnet/blob/main/unet_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/advait416/Grapesnet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hLVZKOl_Ega",
        "outputId": "09591626-d34f-40ad-8d32-a35d2ff9f041"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Grapesnet'...\n",
            "remote: Enumerating objects: 11742, done.\u001b[K\n",
            "remote: Counting objects: 100% (287/287), done.\u001b[K\n",
            "remote: Compressing objects: 100% (286/286), done.\u001b[K\n",
            "remote: Total 11742 (delta 1), reused 287 (delta 1), pack-reused 11455\u001b[K\n",
            "Receiving objects: 100% (11742/11742), 3.31 GiB | 35.71 MiB/s, done.\n",
            "Resolving deltas: 100% (761/761), done.\n",
            "Updating files: 100% (12117/12117), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==v2.14.0"
      ],
      "metadata": {
        "id": "5-OVE1LASemU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94eae6a-5435-4ab3-d654-24c7b6ea9dc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==v2.14.0\n",
            "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (4.5.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==v2.14.0)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (0.33.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==v2.14.0) (1.57.0)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==v2.14.0)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==v2.14.0)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.15,>=2.14.0 (from tensorflow==v2.14.0)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==v2.14.0) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==v2.14.0) (3.2.2)\n",
            "Installing collected packages: wrapt, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.15.0\n",
            "    Uninstalling wrapt-1.15.0:\n",
            "      Successfully uninstalled wrapt-1.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.13.0\n",
            "    Uninstalling tensorflow-estimator-2.13.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.13.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.13.1\n",
            "    Uninstalling keras-2.13.1:\n",
            "      Successfully uninstalled keras-2.13.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.13.0\n",
            "    Uninstalling tensorboard-2.13.0:\n",
            "      Successfully uninstalled tensorboard-2.13.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.13.0\n",
            "    Uninstalling tensorflow-2.13.0:\n",
            "      Successfully uninstalled tensorflow-2.13.0\n",
            "Successfully installed keras-2.14.0 tensorboard-2.14.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PhPHbkYXju5",
        "outputId": "cb061b82-08bd-42fc-d14e-800e7c9b8291"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "LaHN84-LHLu9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir_images = '/content/Grapesnet/Test/Test_set/Images'\n",
        "train_data_dir_masks = '/content/Grapesnet/Test/Train_set/Masks'\n",
        "test_data_dir_images='/content/Grapesnet/Test/Test_set/Images'\n",
        "test_data_dir_masks='/content/Grapesnet/Test/Test_set/Masks'\n"
      ],
      "metadata": {
        "id": "udCHW2qfHQyS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_height, image_width = 256,256\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "_08n7-JFHe5U"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "    drop4 = layers.Dropout(0.5)(conv4)\n",
        "    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "    drop5 = layers.Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = layers.Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
        "    merge6 = layers.concatenate([drop4, up6], axis=3)\n",
        "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
        "    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
        "    merge7 = layers.concatenate([conv3, up7], axis=3)\n",
        "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
        "    merge8 = layers.concatenate([conv2, up8], axis=3)\n",
        "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
        "    merge9 = layers.concatenate([conv1, up9], axis=3)\n",
        "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)  # Change the number of channels to 3\n",
        "\n",
        "    outputs = layers.Conv2D(3, 1, activation='softmax')(conv9)  # Change the number of channels to 3\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Za65cOH0HswS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def load_data(data_dir_images, data_dir_masks, image_height, image_width):\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    # Ensure that the data directories exist\n",
        "    if not os.path.exists(data_dir_images) or not os.path.exists(data_dir_masks):\n",
        "        raise ValueError(\"Data directories do not exist.\")\n",
        "\n",
        "    # List files in the image and mask directories\n",
        "    image_file_list = os.listdir(data_dir_images)\n",
        "    mask_file_list = os.listdir(data_dir_masks)\n",
        "\n",
        "    # Sort the file lists to ensure corresponding images and masks match\n",
        "    image_file_list.sort()\n",
        "    mask_file_list.sort()\n",
        "\n",
        "    # Check if the number of images and masks match\n",
        "    if len(image_file_list) != len(mask_file_list):\n",
        "        raise ValueError(\"Number of images and masks do not match.\")\n",
        "\n",
        "    for image_filename, mask_filename in zip(image_file_list, mask_file_list):\n",
        "        if image_filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            # Load image\n",
        "            img = load_img(\n",
        "                os.path.join(data_dir_images, image_filename),\n",
        "                grayscale=False,  # Set to True if images are grayscale\n",
        "                color_mode='rgb',  # Set to 'grayscale' for grayscale images\n",
        "                target_size=(image_height, image_width)\n",
        "            )\n",
        "            img = img_to_array(img)\n",
        "            images.append(img)\n",
        "\n",
        "            # Load mask\n",
        "            mask = load_img(\n",
        "                os.path.join(data_dir_masks, mask_filename),\n",
        "                target_size=(image_height, image_width)\n",
        "            )\n",
        "            mask = img_to_array(mask)\n",
        "            masks.append(mask)\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PEBl7-hRH-tH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images,train_masks= load_data(train_data_dir_images,train_data_dir_masks,image_height, image_width)\n",
        "test_images, test_masks = load_data(test_data_dir_images,test_data_dir_masks,image_height, image_width)\n",
        "print(train_images.shape)\n",
        "print(train_masks.shape)\n",
        "test_images,test_masks=load_data(test_data_dir_images,test_data_dir_masks,image_height, image_width)\n",
        "print(test_images.shape)\n",
        "print(test_masks.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMmeDIWxI0S8",
        "outputId": "7f7f82db-a735-48b5-f911-0d67e5ffe366"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(140, 256, 256, 3)\n",
            "(140, 256, 256, 3)\n",
            "(140, 256, 256, 3)\n",
            "(140, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2  # OpenCV for image processing (you may need to install it)\n",
        "\n",
        "def preprocess_images(images):\n",
        "    # Normalize pixel values to the range [0, 1]\n",
        "    images = images.astype(np.float32)/ 255.0\n",
        "    print(images.shape)\n",
        "    return images\n",
        "\n",
        "def preprocess_masks(masks):\n",
        "    # Ensure masks have a binary format (0s and 1s)\n",
        "    train_masks_binary = (train_masks > 0).astype(np.uint8)\n",
        "    print(train_masks_binary.shape)\n",
        "    return train_masks_binary\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have loaded train_images and train_masks\n",
        "train_images, train_masks = load_data(train_data_dir_images, train_data_dir_masks, image_height, image_width)\n",
        "\n",
        "# Preprocess and normalize images\n",
        "train_images = preprocess_images(train_images)\n",
        "\n",
        "# Preprocess masks (binary format)\n",
        "train_masks = preprocess_masks(train_masks)\n",
        "\n",
        "# Print the shapes of the preprocessed data\n",
        "print(\"Preprocessed Train Images Shape:\", train_images.shape)\n",
        "print(\"Preprocessed Train Masks Shape:\", train_masks.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHA99zirk-Nv",
        "outputId": "adb03eda-32e2-4f05-dacb-95b099903ce1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(140, 256, 256, 3)\n",
            "(140, 256, 256, 3)\n",
            "Preprocessed Train Images Shape: (140, 256, 256, 3)\n",
            "Preprocessed Train Masks Shape: (140, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_images, test_images, train_masks, test_masks = train_test_split(\n",
        "    train_images, train_masks, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# If you have a specific deep learning framework (e.g., TensorFlow or PyTorch),\n",
        "# you may need to further preprocess the data, such as converting it to tensors.\n",
        "\n",
        "# Example of converting data to tensors using TensorFlow:\n",
        "import tensorflow as tf\n",
        "train_images = tf.convert_to_tensor(train_images, dtype=tf.float32)\n",
        "test_images = tf.convert_to_tensor(test_images, dtype=tf.float32)\n",
        "train_masks = tf.convert_to_tensor(train_masks, dtype=tf.float32)\n",
        "test_masks = tf.convert_to_tensor(test_masks, dtype=tf.float32)\n",
        "\n",
        "# Print the shapes of the data arrays\n",
        "print(\"Train Images Shape:\", train_images.shape)\n",
        "print(\"Test Images Shape:\", test_images.shape)\n",
        "print(\"Train Masks Shape:\", train_masks.shape)\n",
        "print(\"Test Masks Shape:\", test_masks.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idBMjs0wI8L_",
        "outputId": "3d97046c-adf9-4ef4-9d7c-ab005f82dc78"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images Shape: (112, 256, 256, 3)\n",
            "Test Images Shape: (28, 256, 256, 3)\n",
            "Train Masks Shape: (112, 256, 256, 3)\n",
            "Test Masks Shape: (28, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_model((image_height, image_width, 3))  # Adjust input shape according to your data\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8NPnLqf_nTiI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 40 # You can adjust the number of epochs\n",
        "batch_size = 20"
      ],
      "metadata": {
        "id": "y2Yo6utvnxdY"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit (\n",
        "    train_images, train_masks,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2  # You can use a validation split if needed\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aGHtCJNn2MW",
        "outputId": "8f08d9d0-9637-442e-efcb-90df9498452d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3381 - accuracy: 0.3556 - val_loss: 0.3631 - val_accuracy: 0.2468\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3379 - accuracy: 0.2712 - val_loss: 0.3638 - val_accuracy: 0.2126\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3372 - accuracy: 0.3120 - val_loss: 0.3630 - val_accuracy: 0.2678\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3370 - accuracy: 0.3107 - val_loss: 0.3636 - val_accuracy: 0.2040\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3382 - accuracy: 0.2626 - val_loss: 0.3640 - val_accuracy: 0.3000\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3381 - accuracy: 0.3518 - val_loss: 0.3632 - val_accuracy: 0.2460\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3373 - accuracy: 0.2560 - val_loss: 0.3631 - val_accuracy: 0.1693\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3369 - accuracy: 0.2413 - val_loss: 0.3632 - val_accuracy: 0.2653\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3367 - accuracy: 0.2825 - val_loss: 0.3638 - val_accuracy: 0.2688\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3371 - accuracy: 0.2760 - val_loss: 0.3622 - val_accuracy: 0.2551\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3371 - accuracy: 0.2718 - val_loss: 0.3629 - val_accuracy: 0.2625\n",
            "Epoch 12/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3376 - accuracy: 0.3555 - val_loss: 0.3636 - val_accuracy: 0.3267\n",
            "Epoch 13/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3369 - accuracy: 0.3315 - val_loss: 0.3636 - val_accuracy: 0.2158\n",
            "Epoch 14/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3373 - accuracy: 0.2509 - val_loss: 0.3638 - val_accuracy: 0.2357\n",
            "Epoch 15/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3365 - accuracy: 0.3255 - val_loss: 0.3634 - val_accuracy: 0.2854\n",
            "Epoch 16/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3381 - accuracy: 0.3431 - val_loss: 0.3641 - val_accuracy: 0.2272\n",
            "Epoch 17/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3377 - accuracy: 0.2616 - val_loss: 0.3648 - val_accuracy: 0.2224\n",
            "Epoch 18/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3378 - accuracy: 0.3325 - val_loss: 0.3626 - val_accuracy: 0.2697\n",
            "Epoch 19/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3372 - accuracy: 0.3239 - val_loss: 0.3642 - val_accuracy: 0.2187\n",
            "Epoch 20/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3369 - accuracy: 0.2647 - val_loss: 0.3632 - val_accuracy: 0.2990\n",
            "Epoch 21/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3390 - accuracy: 0.3130 - val_loss: 0.3647 - val_accuracy: 0.3116\n",
            "Epoch 22/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3390 - accuracy: 0.3407 - val_loss: 0.3659 - val_accuracy: 0.2410\n",
            "Epoch 23/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3378 - accuracy: 0.3123 - val_loss: 0.3631 - val_accuracy: 0.2390\n",
            "Epoch 24/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3375 - accuracy: 0.3615 - val_loss: 0.3623 - val_accuracy: 0.2901\n",
            "Epoch 25/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3372 - accuracy: 0.3102 - val_loss: 0.3627 - val_accuracy: 0.1808\n",
            "Epoch 26/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3386 - accuracy: 0.2074 - val_loss: 0.3644 - val_accuracy: 0.3217\n",
            "Epoch 27/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3388 - accuracy: 0.4284 - val_loss: 0.3646 - val_accuracy: 0.2903\n",
            "Epoch 28/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3390 - accuracy: 0.2646 - val_loss: 0.3645 - val_accuracy: 0.1219\n",
            "Epoch 29/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3380 - accuracy: 0.1657 - val_loss: 0.3632 - val_accuracy: 0.2894\n",
            "Epoch 30/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3373 - accuracy: 0.3550 - val_loss: 0.3634 - val_accuracy: 0.3491\n",
            "Epoch 31/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3371 - accuracy: 0.2927 - val_loss: 0.3626 - val_accuracy: 0.1797\n",
            "Epoch 32/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3380 - accuracy: 0.1795 - val_loss: 0.3656 - val_accuracy: 0.2320\n",
            "Epoch 33/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3373 - accuracy: 0.3636 - val_loss: 0.3632 - val_accuracy: 0.3649\n",
            "Epoch 34/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3370 - accuracy: 0.3335 - val_loss: 0.3654 - val_accuracy: 0.1799\n",
            "Epoch 35/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3369 - accuracy: 0.2486 - val_loss: 0.3643 - val_accuracy: 0.2848\n",
            "Epoch 36/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3373 - accuracy: 0.3900 - val_loss: 0.3620 - val_accuracy: 0.3586\n",
            "Epoch 37/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3375 - accuracy: 0.2994 - val_loss: 0.3636 - val_accuracy: 0.1631\n",
            "Epoch 38/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3375 - accuracy: 0.2070 - val_loss: 0.3631 - val_accuracy: 0.2946\n",
            "Epoch 39/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3367 - accuracy: 0.3491 - val_loss: 0.3627 - val_accuracy: 0.3028\n",
            "Epoch 40/40\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3369 - accuracy: 0.3032 - val_loss: 0.3635 - val_accuracy: 0.1976\n"
          ]
        }
      ]
    }
  ]
}